from proveit._core_.expression.expr import (Expression, MakeNotImplemented,
                                            ImproperSubstitution, 
                                            DisallowedIndexing)
from proveit._core_.expression.lambda_expr.lambda_expr import Lambda
from proveit._core_.expression.composite import singularExpression, ExprTuple
from proveit._core_.expression.conditional import Conditional
from proveit._core_.proof import ProofFailure
from proveit._core_.defaults import defaults, USE_DEFAULTS

class ExprRange(Expression):
    '''
    An ExprRange expression represents a range of "element" expressions
    within a containing ExprTuple.  It represents this as a Lambda to 
    map each valid index value to a corresponding element, along with a
    start and end index value.  The represented element sequence 
    corresponds to index values going from the start to the end in 
    increments of 1, ranging over index values.
    
    For example,
    1/i + ... + 1/j
    is internall represented by an Add operation with the following as 
    its "operands":
    (1/i, ..., 1/j).
    These "operands" are represented by an ExprTuple with a single 
    "entry" which is an ExprRange whose `lambda_map` is "k |-> 1/k", 
    `start_index` is "i", and `end_index` is "j".  An ExprTuple "entry" 
    may generally either be a singuler element or an ExprRange that 
    represents multiple elements.
    '''

    def __init__(self, parameter, body, start_index, end_index, 
                 lambda_map=None):
        '''
        Create an ExprRange that represents a range of expressions
        to be embedded within an ExprTuple.  Each element of the
        range is generated by mapping the parameter according to the
        body with the parameter ranging from the start index to the
        end index. 
        A Lambda expression will be created as its first sub-expression.
        The start and end indices with be the second and third
        sub-expressions.
        
        The lambda_map may be used instead of supplying the parameter 
        and body, in which case the 'parameter' and 'body' arguments
        must both be None.
        '''
        if lambda_map is not None:
            # Use the provided 'lambda_map' instead of creating one.
            lambda_map = lambda_map
            if (parameter, body) != (None, None):
                raise ValueError("'parameter' and 'body' arguments of the "
                                 "ExprRange constructor should be None if "
                                 "lambda_map is provided.")
            parameter = lambda_map.parameter
        else:
            lambda_map = Lambda(parameter, body)
        
        Expression.__init__(self, ['ExprRange'], 
                            [lambda_map, start_index, end_index])
        self.start_index = singularExpression(start_index)
        self.end_index = singularExpression(end_index)
        self.lambda_map = lambda_map
        # The body of the Lambda map is a Conditional that conditions the 
        # mapping according to the parameter being in the [start, end] 
        # interval.  We'll use self.body to refer to the value of this
        # conditional.
        self.parameter = self.lambda_map.parameter
        self.body = self.lambda_map.body
    
    @classmethod
    def _make(subClass, coreInfo, styles, subExpressions):
        if subClass != ExprRange: 
            MakeNotImplemented(subClass)
        if len(coreInfo) != 1 or coreInfo[0] != 'ExprRange':
            raise ValueError("Expecting ExprRange coreInfo to contain "
                             "exactly one item: 'ExprRange'")
        lambda_map, start_index, end_index = subExpressions
        return ExprRange(None, None, start_index, end_index, 
                         lambda_map=lambda_map) \
                .withStyles(**styles)
            
    def remakeArguments(self):
        '''
        Yield the argument values or (name, value) pairs
        that could be used to recreate the ExprRange.
        '''
        yield self.lambda_map.parameter
        yield self.lambda_map.body
        yield self.start_index
        yield self.end_index
        
    def first(self):
        '''
        Return the first instance of the range 
        (and store for future use).
        '''
        if not hasattr(self, '_first'):
            expr_map = {self.lambda_map.parameter:self.start_index}
            self._first =  self.body.substituted(expr_map)
        return self._first

    def last(self):
        '''
        Return the last instance of the range 
        (and store for future use).
        '''
        if not hasattr(self, '_last'):
            expr_map = {self.lambda_map.parameter:self.end_index}
            self._last = self.body.substituted(expr_map)
        return self._last
        
    def string(self, **kwargs):
        return self.formatted('string', **kwargs)

    def latex(self, **kwargs):
        return self.formatted('latex', **kwargs)
    
    def nested_range_depth(self):
        '''
        Return the depth of nested ranges.  For example, if this
        is a simple range with no nesting, return 1.
        If this is a range of simple ranges, return 2.
        If this is a range of ranges of simple ranges, return 3.
        '''
        depth = 1
        expr = self.body
        while isinstance(expr, ExprRange):
            depth += 1
            expr = expr.body
        return depth
        
    def formatted(self, formatType, fence=False, subFence=True, 
                  operator=None, **kwargs):
        if operator is None:
             # comma is the default formatted operator
            formatted_operator = ','
        elif isinstance(operator, str):
            formatted_operator = operator
        else:
            formatted_operator = operator.formatted(formatType)
        formatted_sub_expressions = \
            [subExpr.formatted(formatType, fence=subFence) 
             for subExpr in (self.first(), self.last())]
        ellipsis = ('\ldots' if formatType=='latex' 
                                             else '...')
        # When ranges are nested, double-up (or triple-up, etc)
        # the ellipsis to make the nested structure clear.
        ellipses = ellipsis*self.nested_range_depth()
        
        formatted_sub_expressions.insert(1, ellipses)
        # Normally the range will be wrapped in an ExprTuple and 
        # fencing will be handled externally.  When it isn't, we don't 
        # want to fence it  anyway.
        return formatted_operator.join(formatted_sub_expressions)
    
    def getInstance(self, index, assumptions = USE_DEFAULTS, 
                    requirements = None):
        '''
        Return the range instance with the given Lambda map
        index as an Expression, using the given assumptions as 
        needed to interpret the index expression.  Required
        truths, proven under the given assumptions, that 
        were used to make this interpretation will be
        appended to the given 'requirements' (if provided).
        '''
        from proveit.number import LessEq
        
        if requirements is None:
            # requirements won't be passed back in this case 
            requirements = [] 
        
        # first make sure that the indices are in the range
        start_index, end_index = self.start_index, self.end_index
        for first, second in ((start_index, index), (index, end_index)):
            relation = None
            try:
                relation = LessEq.sort([first, second], reorder=False, 
                                       assumptions=assumptions)
            except:
                raise RangeInstanceError(
                        "Indices not provably within the range "
                        "range: %s <= %s"%(first, second)) 
            requirements.append(relation)
        
        # map to the desired instance
        return self.lambda_map.apply(index, assumptions=assumptions,
                                     requirements=requirements)
    
    def _possibly_reduced_range(self, expr_range, assumptions, requirements):
        from proveit import KnownTruth
        from proveit._common_ import f, i, j
        from proveit.logic import Equals
        from proveit.number import Add, one
        if not defaults.automation:
            # If automation is off, we won't do any reduction.
            yield expr_range
            return
        lambda_map = expr_range.lambda_map
        start_index = expr_range.start_index
        end_index = expr_range.end_index
        if defaults.reduce_singular_ranges and start_index == end_index:
            # We can do a singular range reduction.
            # Temporarily disable automation to avoid infinite
            # recursion.
            from proveit.core_expr_types.tuples._theorems_ import \
                singular_range_reduction
            defaults.automation = False
            try:
                reduction = singular_range_reduction.instantiate(
                        {f:lambda_map, i:start_index})
            finally:
                # Re-enable automation.
                defaults.automation = True
        elif (defaults.reduce_empty_ranges and 
              Equals(Add(end_index, one), start_index).proven(assumptions)):
            # We can do an empty range reduction
            # Temporarily disable automation to avoid infinite
            # recursion.
            from proveit.core_expr_types.tuples._axioms_ import empty_range_def
            defaults.automation = False
            try:
                reduction = empty_range_def.instantiate(
                        {f:lambda_map, i:start_index, j:end_index})
            finally:
                # Re-enable automation.
                defaults.automation = True                
        else:
            yield expr_range # no reduction
            return
        assert isinstance(reduction, KnownTruth)
        assert isinstance(reduction.expr, Equals)
        assert len(reduction.expr.operands) == 2
        assert reduction.expr.operands[0] == ExprTuple(expr_range)
        reduced_tuple = reduction.expr.operands[1]
        assert isinstance(reduced_tuple, ExprTuple)
        requirements.append(reduction)
        for entry in reduced_tuple:
            yield entry
    
    def _substituted_entries(self, repl_map, allow_relabeling=False,
                             assumptions=USE_DEFAULTS, 
                             requirements=None):
        '''
        Returns this expression with sub-expressions substituted 
        according to the replacement map (repl_map) dictionary.
        
        'assumptions' and 'requirements' are used when an operator is
        substituted by a Lambda map that has a range of parameters such 
        that the length of the parameters and operands must be proven 
        to be equal.  See the Operation.substituted and Lambda.apply 
        documentation for more details.
        
        There are limitations with respect to applying a Lambda map with
        ExprRange parameters that are enforced here in 
        ExprRange.substituted.
        
        First, ExprRange parameter variables must only be contained in 
        an IndexedVar with indices covering the same range (same 
        start and end argument) as the ExprRange parameter itself,
        up to constant, integer shifts.
        The following example meets this restriction.
        
        Applying the Lambda
        (x, y_1, ..., y_3, z_i, ..., z_{j+1}) -> 
            x*y_1 + ... + x*y_3 + z_i*z_{i+1} + ... + z_j*z_{j+1}
        to operands (a, b, c, d, e_m, ..., e_n, f)
        will result in 
           a*b + a*c + a*d + e_m*e_{m+1} + ... _ e_{n-1}*e_n + e_n*f 
        under the following requirements
        |(b, c, d)| = |(1, ..., 3)| 
        |(e_m, ..., e_n, f)| = |(i, ..., j+1)| 
        (e_m, ..., e_n) = (e_m, ..., e_{n-1}, e_n)
        (proven in advance or via automation).
        
        A counter-example not meeting the restriction is
        (x_1, ..., x_n) -> x_1 * ... * x_j
        since the 'n' and 'j' do not match.
        
        Second, all expanded indexed variables within an ExprRange must
        have matching expansions up to constant, integer shifts of
        the ExprRange's of the expansions.  For example,
        (x_1, ..., x_n, y_1, ..., y_n) -> x_1*y_1 + ... + x_n*y_n
        may be applied to
        (a_1, ..., a_{n-1}, b, c_1, ..., c_{n-1}, d)
        to produce 
        a_1*c_1 + ... + a_{n-1}*c_{n-1} + b*d
        and may be applied to
        (a, b_1, ..., b_{n-1}, c_1, ..., c_{n-1}, d)
        to produce
        a*c_1 + b_1*c_{1+1} * ... * b_{n-2}*c_{(n-2)+1} + b_{n-1}*d
        but may NOT be applied to
        (a_1, ..., a_n, c_1, ..., c__k)
        
        In order to handle these restricted cases, transformations must 
        be made to bring the ranges of indexed variables into alignment.
        Use methods such as Lambda.relabeled, ExprRange.partition, or 
        ExprRange.split to do this.
        
        See the Lambda.apply documentation for a related discussion.
        '''
        from proveit.logic import Equals #, InSet
        from proveit.number import Add, one #, Interval
        from proveit.number import (const_shift_decomposition,
                                    const_shift_composition)
                        
        if len(repl_map)>0 and (self in repl_map):
            # The full expression is to be substituted.
            return repl_map[self]
        
        assumptions = defaults.checkedAssumptions(assumptions)
        new_requirements = []
        lambda_map = self.lambda_map
        orig_parameter = self.parameter
        
        subbed_start = self.start_index.substituted(
                repl_map, allow_relabeling, assumptions, requirements)
        subbed_end = self.end_index.substituted(
                repl_map, allow_relabeling, assumptions, requirements)
        
        # Check if any of the IndexedVars whose index is the ExprRange
        # parameter (or a shifted version of this parameter)
        # is being expanded by the repl_map.
        must_expand = False
        first_expanded_indexed_var = None
        indexed_vars_of_range = self.body._free_indexed_vars(self.parameter)
        for indexed_var in indexed_vars_of_range:
            indexed_var_repl = repl_map.get(indexed_var.var, None)
            # When being expanded, replacement of an indexed_var.var 
            # should be the broadest contiguous range over which its
            # indices here are free.  For example:
            # x : (x_1, ..., x_{n+1})
            # The corresponding value will be a key in repl_map for
            # the real expansion in correspondence with these indices.
            if isinstance(indexed_var_repl, ExprTuple):
                first_expanded_indexed_var = indexed_var
                must_expand = True
        
        if not must_expand:
            # No need to worry about expanding IndexedVar's.
            # However, we may perform a reduction of the range
            # if it is known to be empty or singular.
            subbed_lambda_map = lambda_map.substituted(
                    repl_map, allow_relabeling, assumptions, requirements)
            subbed_expr = ExprRange(None, None, subbed_start, subbed_end, 
                                    lambda_map = subbed_lambda_map)
            for entry in self._possibly_reduced_range(subbed_expr, 
                                                      assumptions, 
                                                      requirements):
                yield entry
            return
        
        # Need to expand IndexedVar's.  The expansions must be defined 
        # over the start/end range and must be aligned with each 
        # other.
        
        # If the range parameter is used for anything other than an
        # IndexedVar, or not all of the IndexedVars that are indexed by
        # the range parameter, all of the new indices must match the 
        # original indices, not just the length.
        remaining_free_vars = \
            self.body._free_vars(exclusions=indexed_vars_of_range)
        indices_must_match = (self.parameter in remaining_free_vars)
        if indices_must_match:
            reason_indices_must_match = (
                    "the ExprRange parameter appears outside of IndexedVar "
                    "indices")
        
        # Separate the 'base' from any constant integer shift
        # for the subbed start and end indices.
        start_base, start_shift = const_shift_decomposition(subbed_start)
        end_base, end_shift = const_shift_decomposition(subbed_end)

        # When being expanded, replacement of an indexed_var.var 
        # should be the broadest contiguous range over which its
        # indices here are free.  For example:
        # x : (x_1, ..., x_{n+1})
        # The corresponding value will be a key in repl_map for
        # the real expansion in correspondence with these indices.
        # The 'base' of the start and end indices of this
        # range must match those of this ExprRange for a proper 
        # substitution.
        indexed_var_expansion = dict() 
        for indexed_var in indexed_vars_of_range:
            # indexed_var_range_tuple should be something like 
            # (x_i, ..., x_j)
            # where the 'base' of i and j match the 'base' of 
            # the start and end indices of this ExprRange (the 'base'
            # excludes any constant integer offset).
            indexed_var_range_tuple = repl_map.get(indexed_var.var, None)
            if isinstance(indexed_var_range_tuple, ExprTuple):
                if len(indexed_var_range_tuple) != 1 \
                        or not isinstance(indexed_var_range_tuple[0], 
                                          ExprRange):
                    raise ImproperSubstitution(
                            "Improper indexed variable expansion: expecting "
                            "the repl_map value for '%s' to be an "
                            "ExprTuple with a single ExprRange "
                            "of indexed variables, got '%s' instead."
                            %(indexed_var.var, indexed_var_range_tuple))
                
                # If the IndexedVars are not all expanded together,
                # we must match the new indices with the old indices, 
                # not just the length.
                if not indices_must_match:
                    indices_must_match = True
                    reason_indices_must_match = (
                            "not all of the indexed variables being indexed "
                            "by the ExprRange parameter are being expanded "
                            "(%s is expanded but %s is not)"
                            %(first_expanded_indexed_var.var, indexed_var.var))
                continue
            
            # Check that the 'bases' match appropriately.
            indexed_var_range = indexed_var_range_tuple[0]
            repl_start_base, repl_start_shift = \
                const_shift_decomposition(indexed_var_range.start_index)
            repl_end_base, repl_end_shift = \
                const_shift_decomposition(indexed_var_range.end_index)
            if repl_start_base != start_base or repl_end_base != end_base:
                raise ImproperSubstitution(
                        "Improper indexed variable expansion: "
                        "the range of %s .. %s for the expansion of %s "
                        "must match %s .. %s up to explicit contant integer "
                        "shifts (e.g., n+1 has a shift of 1)."
                        %(indexed_var_range.start_index, 
                          indexed_var_range.end_iundex, indexed_var.var,
                          subbed_start, subbed_end))
            index_base, index_shift = const_shift_decomposition(
                    indexed_var.index)
            assert index_base==self.parameter
            
            repl = repl_map.get(indexed_var_range_tuple, 
                                indexed_var_range_tuple)
            rel_start_idx = start_shift+index_shift-repl_start_shift
            rel_end_idx = end_shift+index_shift-repl_end_shift
            repl = repl.extract_portion(
                    rel_start_idx, rel_end_idx, assumptions=assumptions,
                    requirements=requirements)
            indexed_var_expansion[indexed_var] = repl.entries()
    
        def raise_failed_simultaneous_finish(finished_expression, 
                                             unfinished_expression):
            raise ImproperSubstitution(
                    "IndexedVar expansions failed to finish simultanously; "
                    "%s have finished while %s have not."
                    %(finished_expression, unfinished_expression))
        
        def raise_failed_base_match(indexed_var1, start_base1, end_base1,
                                    indexed_var2, start_base2, end_base2):
            raise ImproperSubstitution(
                    "When expanding IndexedVar's within an ExprRange with "
                    "indices dependent upon the ExprRange parameter, their "
                    "expansion ExprRange indices must all match up to "
                    "explicit constant shifts. %s..%s for %s does not "
                    "match with %s vs %s for %s."
                    %(start_base1, end_base1, indexed_var1,
                      start_base2, end_base2, indexed_var2))

        def raise_failed_length_match(indexed_var1, start_index1, end_index1,
                                      indexed_var2, start_index2, end_index2):
            raise ImproperSubstitution(
                    "When expanding IndexedVar's within an ExprRange with "
                    "indices dependent upon the ExprRange parameter, their "
                    "expansion ExprRange lengths must all match. " 
                    "%s..%s for %s does not match in length with "
                    "with %s vs %s for %s."
                    %(start_index1, end_index1, indexed_var1,
                      start_index2, end_index2, indexed_var2))
        
        # Need to handle the change in scope within the lambda 
        # expression.  We won't use 'new_params'.  They aren't relavent 
        # after an expansion, this won't be used.
        new_params, inner_repl_map, inner_assumptions \
            = self.lambda_map._inner_scope_sub(repl_map, assumptions, 
                                               new_requirements)
        assert len(new_params)==1
        new_param = new_params[0]
        
        if indices_must_match:
            # We do need to match the new indices to the original indices.
            # Prepare to do that.
            new_indices = []
            next_index = subbed_start
        
        # Loop over the entries of the first expansion which must be
        # in correspondence (same ExprRange range or the same in being 
        # singular) with the other expansions.
        body = self.body
        orig_expansions = list(indexed_var_expansion.values())
        first_indexed_var = indexed_var_expansion.keys()[0]
        while True:
            next_entries = [expansion[0] for expansion 
                             in indexed_var_expansion.values()
                             if len(expansion) > 0]
            if len(next_entries) == 0:
                break # everything finished
            if len(next_entries) < len(indexed_var_expansion):
                # One (or some) of the expansions finished before 
                # others.  That is is failure.
                finished_expansions = []
                unfinished_expansions = []
                for orig_expansion, expansion in zip(
                        orig_expansions, indexed_var_expansion.values()):
                    if len(expansion) == 0: 
                        finished_expansions.append(orig_expansion)
                    else:
                        unfinished_expansions.append(orig_expansion)
                raise_failed_simultaneous_finish(
                        finished_expansions, unfinished_expansions)                
                
            if any(not isinstance(entry, ExprRange) for entry in next_entries):
                # If any of the next entries are singular entries,
                # peel singular entries all of all of them.
                entry_repl_map = dict(inner_repl_map)
                for indexed_var, entry in zip(indexed_var_expansion.keys(), 
                                              next_entries):
                    if isinstance(entry, ExprRange):
                        # Partition to peel off a singular entry.
                        req = entry.partition(entry.start_index, assumptions)
                        requirements.append(req)
                        partitioned = req.rhs
                        assert isinstance(partitioned, ExprTuple)
                        assert len(partitioned) == 2
                        # Use the peeled-off singular entry.
                        entry_repl_map[indexed_var] = partitioned[0]
                        # Insert the remainder of the range as the
                        # next, next entry.
                        indexed_var_expansion[indexed_var].insert(
                                0, partitioned[1])
                # For a singular element entry, yield the substituted
                # element.
                if indices_must_match:
                    # The actual range parameter index is needed:
                    entry_repl_map[orig_parameter] = next_index
                if isinstance(body, ExprRange):
                    # A nested ExprRange may need to be expanded.
                    for subentry in body._substituted_entries(
                            entry_repl_map, inner_assumptions, requirements):
                        yield subentry
                else:
                    yield body.substituted(entry_repl_map, allow_relabeling,
                                           inner_assumptions, requirements)
                if indices_must_match:
                    # We need to know the new_indices to match with the
                    # original indices.
                    new_indices.append(next_index)
                    next_index = Add(next_index, one).simplified(assumptions)            
            else:
                # The next entries are all ExprRange's.
                # Make sure they all have the same start and end
                # index 'bases'.
                start_base, end_base = None, None
                shift_delta = None
                start_shifts = set()
                for entry in next_entries:
                    kth_start_base, kth_start_shift = \
                        const_shift_decomposition(entry.start_index)
                    kth_end_base, kth_end_shift = \
                        const_shift_decomposition(entry.end_index)
                    start_shifts.add(kth_start_shift)
                    if start_base is None:
                        start_base, end_base = kth_start_base, kth_end_base
                    elif (kth_start_base != start_base 
                            or kth_end_base != end_base):
                        # Start/end bases fail to match.
                        raise_failed_base_match(
                                first_indexed_var, start_base, end_base,
                                indexed_var, kth_start_base, kth_end_base)
                    if shift_delta is None:
                        shift_delta = kth_end_shift-kth_start_shift
                    elif shift_delta != kth_end_shift-kth_start_shift:
                        # Range spans given start/end shifts fail
                        # to match.
                        raise_failed_length_match(
                                first_indexed_var, next_entries[0].start_index,
                                next_entries[0].end_index, indexed_var,
                                entry.start_index, entry.end_index)
                # We need to choose actual start and end indices.
                # By convention, we'll choose the minimum start shift.
                start_shift = min(start_shifts)
                start_index = const_shift_composition(start_base, start_shift)
                end_index = const_shift_composition(start_base, 
                                                    start_shift+shift_delta)
                for indexed_var, entry in zip(indexed_var_expansion.keys(), 
                                              next_entries):
                    if entry.start_index != start_index:
                        # Do a shift so the start/end indices match
                        # exactly.
                        _, old_shift = \
                            const_shift_composition(indexed_var.index)
                        req = entry.shift_equivalence(
                                old_shift=old_shift, new_start=start_index, 
                                new_end=end_index, assumptions=assumptions)
                        requirements.append(req)
                        shifted = req.rhs
                        assert isinstance(shifted, ExprTuple)
                        assert len(shifted) == 1
                        # Use the shifted version.
                        entry = shifted
                    # Relabel the entry body to use the parameter of 
                    # this ExprRange so that all the parameters will be 
                    # consistent.
                    new_body = entry.body.substituted(
                            {entry.parameter:new_param})
                    # For this entry, replace the IndexedVar with the 
                    # corresponding ExprRange body.
                    entry_repl_map[indexed_var] = new_body                        
                
                # Let's keep this simple.  If it isn't really necessary
                # to be so fancy with this internal assumption about
                # being in the [start, end] interval, let's not do it.
                # If needed, we can use explicit axioms/theorems to
                # make use of this property rather than in the core.
                #range_assumption = InSet(new_param, 
                #                         Interval(start_index, end_index))
                
                entry_assumptions = inner_assumptions # + [range_assumption]
                entry_requirements = []
                entry_repl_map[orig_parameter] = new_param
                entry = ExprRange(new_param,
                             body.substituted(entry_repl_map,
                                              entry_assumptions, 
                                              entry_requirements),
                             start_index, end_index)
                # We may perform a reduction of the range if it is known
                # to be empty or singular.
                for entry in self._possibly_reduced_range(entry, 
                                                          assumptions, 
                                                          requirements):
                    yield entry
                if indices_must_match:
                    # We need to know the new_indices to match with the
                    # original indices.
                    new_indices.append(ExprRange(new_param, new_param, 
                                            start_index, end_index))
                    next_index = Add(end_index, one).simplified(assumptions)
                # Translate from inner requirements to outer requirements
                # in a manner that respects the change in scope w.r.t.
                # lambda parameters.
                for requirement in entry_requirements:
                    if new_param in requirement._free_vars():
                        # If the requirement involves the ExprRange 
                        # parameter, it must be generalized under these
                        # parameters to ensure there is no scoping 
                        # violation since this parameter's scope is
                        # within the new ExprRange.
                        conditions = requirement.assumptions
                        requirement = requirement.generalize(
                                new_param, conditions=conditions)
                    requirements.append(requirement)
        
        if indices_must_match:
            # The range parameter appears outside of
            # IndexedVars.  That means that we must match new
            # and original indices precisely, not just their length.
            requirement = Equals(ExprTuple(*new_indices), 
                                 ExprTuple(ExprRange(new_param, new_param,
                                                     subbed_start, subbed_end)))
            try:
                requirements.append(requirement.prove(assumptions))
            except ProofFailure as e:
                raise ImproperSubstitution(
                        "ExprRange indices failed to match expansion "
                        "which is necessary because %s: %s."
                        %(reason_indices_must_match, e))
    
    def _free_var_indices(self):
        '''
        Returns a dictionary that maps indexed variables to
        a tuple with (start_base, start_shifts, end_base, end_shifts)
        indicating the indices for which an indexed variable is free.
        The start_shifts and end_shifts are constant integers.
        The included indices are each start_base + start_shift,
        each end_base + end_shift plus the range going from
        start_base + max(start_shifts) .. end_base + min(end_shifts).
        '''
        from proveit.number import const_shift_decomposition
        # Start from the default:
        results = Expression._free_var_indices(self)
        print('default results', results)
        body_free_var_indices = self.body._free_var_indices()
        for var, (start_base, start_shifts, end_base, end_shifts) \
                in body_free_var_indices.items():
            if start_base == end_base == self.parameter:
                # The index base is the range parameter, so we
                # need to upgrade the indices to cover the range.
                start_base, start_shift = \
                    const_shift_decomposition(self.start_index)
                end_base, end_shift = \
                    const_shift_decomposition(self.end_index)
                # When the start and end bases are the same, the
                # shifts are expected to be the same.
                assert start_shifts==end_shifts
                start_shifts = {start_shift+shift for shift in start_shifts}
                end_shifts = {end_shift+shift for shift in end_shifts}
                results[var] = (start_base, start_shifts, end_base, end_shifts)
            elif (self.parameter in start_base._free_vars()
                    or self.parameter in end_base._free_vars()):
                raise DisallowedIndexing(
                        var, 'range', start_base, end_base,
                        range_parameter=self.parameter)     
            else:
                # Indices don't involve the ExprRange parameter,
                # so let them through
                results[var] = \
                    (start_base, start_shifts, end_base, end_shifts)
        print('new ExprRange results', results)
        return results
    
    def partition(self, before_split_idx, assumptions=USE_DEFAULTS):
        '''
        Return the equation between this range within an ExprTuple
        and a split version in the following manner: 
            (f(self.start_index), ..., f(self.end_index)) =
            (f(self.start_index), ..., f(before_split_index), 
             f(before_split_index+1), ..., f(self.end_index))
        where f represents the self.lambda_map.
        '''
        from proveit._common_ import f, i, j, k
        from proveit.logic import Equals
        from proveit.number import Add, one, subtract
        from proveit.core_expr_types.tuples._axioms_ import (
                range_extension_def)
        from proveit.core_expr_types.tuples._theorems_ import (
                partition_front, partition_back, partition)
        
        lambda_map = self.lambda_map
        start_index, end_index = self.start_index, self.end_index
        if end_index == Add(before_split_idx, one):
            # special case which uses the axiom:
            return range_extension_def.specialize(
                    {f:lambda_map, i:start_index, j:before_split_idx},
                    assumptions=assumptions)
        elif before_split_idx == self.start_index:
            # special case when peeling off the front
            return partition_front.specialize(
                    {f:lambda_map, i:self.start_index, j:self.end_index},
                     assumptions=assumptions)
        elif (before_split_idx == subtract(end_index, one) or
              Equals(before_split_idx, subtract(end_index, one)).proven(assumptions)):
            # special case when peeling off the back
            return partition_back.specialize(
                    {f:lambda_map, i:start_index, j:end_index},
                     assumptions=assumptions)
        else:
            return partition.specialize(
                    {f:lambda_map, i:start_index, j:before_split_idx,
                     k:end_index}, assumptions=assumptions)
    
    def shift_equivalence(self, *, old_shift=None, new_start=None, 
                          new_end=None, new_shift=None, 
                          assumptions=USE_DEFAULTS):
        '''
        Return the equation between this range within an ExprTuple
        and a shifted version in the following manner: 
            (f(self.start_index+old_shift), ..., f(self.end_index+old_shift)) =
            (f(new_start+new_shift), ..., f(new_start+new_shift))
        where f is adapted from self.lambda_map according to 'old_shift'.
        If any of the 'new' parameters are unspecified, we attempt 
        to deduce them from the other parameters.
        '''
        from proveit._common_ import a, b, f, i, j, k, l
        from proveit.number import Add, Neg, subtract
        from proveit._core_.expression.label.var import safeDummyVar
        from proveit.core_expr_types.tuples._theorems_ import (
                shift_equivalence, shift_equivalence_both)
        
        if old_shift is None:
            _f = self.lambda_map
        else:
            old_shifted_param = Add(self.parameter, old_shift)
            safe_var = safeDummyVar(self.body)
            shifted_body = self.body.substituted({old_shifted_param:safe_var})
            if self.parameter in shifted_body._free_vars():
                raise ValueError("The given 'old_shift' of %s does apply "
                                 "to %s"%(old_shift, self.lambda_map))
            _f = Lambda(self.parameter, 
                        shifted_body.substituted({safe_var:self.parameter}))
        
        _i, _j = self.start_index, self.end_index
        
        if new_shift is not None:
            net_shift = new_shift
            if old_shift is not None:
                net_shift = subtract(new_shift, old_shift).simplified(
                        assumptions=assumptions)
            if new_start is None:
                # new start = _i - new_shift
                new_start = subtract(_i, net_shift).simplified(
                        assumptions=assumptions)
            if new_end is None:
                # new_end = _j - new_shift
                new_end = subtract(_j, net_shift).simplified(
                        assumptions=assumptions)
        elif new_start is None:
            # new_start = new_end + i - j
            new_end = Add(new_start, _i, Neg(_j)).simplified(
                                  assumptions=assumptions)
        elif new_end is None:
            # new_end = new_start + j - i
            new_end = Add(new_start, _j, Neg(_i)).simplified(
                                  assumptions=assumptions)
        
        _k, _l = new_start, new_end
        
        if new_shift is None:
            # Compute the new shift based upon the other parameters.
            if old_shift is None:
                new_shift = subtract(_i, _k).simplified(assumptions=assumptions)
            else:
                new_shift = Add(_i, old_shift, Neg(_k)).simplified(
                        assumptions=assumptions)
        
        if old_shift is None:
            return shift_equivalence.instantiate(
                    {f:_f, a:new_shift, i:_i, j:_j, k:_k, l:_l}, 
                    assumptions=assumptions)
        else:
            return shift_equivalence_both.instantiate(
                    {f:_f, a:old_shift, b:new_shift, i:_i, j:_j, k:_k, l:_l},
                     assumptions=assumptions)    
    def _var_index_shifts_in_ranges(self, var, shifts):
        '''
        Given a 'var' (e.g., 'x'), pass back, via the set 'shifts', 
        all of the constant indexed shifts to the ExprRange parameter
        within ExprRanges (e.g., 'x_{1+1}, ..., x_{n+1}' would have
        presumably have a shift of 1).
        '''
        self.body._indexed_var_shifts(var, self.parameter, shifts)
        Expression._var_index_shifts_in_ranges(self, var, shifts)
    
    """
    TODO: change register_equivalence_method to allow and fascilitate these
    method stubs for purposes of generating useful documentation.

    def partitioned(self, before_split_idx, assumptions=USE_DEFAULTS):
        '''
        Return the right-hand-side of a 'partition'.
        '''
        raise Exception("Should be implemented via InnerExpr.register_equivalence_method")
    
    def split(self, before_split_idx, assumptions=USE_DEFAULTS):
        '''
        As an InnerExpr method when the inner expression is an ExprRange,
        return the expression with the inner expression replaced by its
        'partitioned' version.
        '''
        raise Exception("Implemented via InnerExpr.register_equivalence_method "
                        "only to be applied to an InnerExpr object.")
    """


def varRange(var, start, end):
    from proveit import safeDummyVar, IndexedVar
    param = safeDummyVar(var)
    return ExprRange(param, IndexedVar(var, param), start, end)

class RangeInstanceError(Exception):
    def __init__(self, msg):
        self.msg = msg
    def __str__(self):
        return self.msg
